{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_creator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_creator_class():\n",
    "    \"\"\"\n",
    "    data creator class splits data into training and testing test and prepares for the training\n",
    "    \"\"\"\n",
    "    def __init__(self,split_ratio):\n",
    "        \"\"\"\n",
    "        init function imports the names.csv data and convers it into numpy array for preprocessing and further usage\n",
    "        \n",
    "        split ratio:- to split data into train and test, takes vaue between 0 and 1\n",
    "        \"\"\"\n",
    "        self.split_ratio = split_ratio\n",
    "        work_path = \"D:/Chrome_downloads/name_identifier/\"\n",
    "        data_path = work_path + \"resources/\"\n",
    "        self.save_data_path = work_path + \"data/\"\n",
    "        self.total_data = pd.read_csv(data_path+\"names.csv\")\n",
    "        self.total_data.shape\n",
    "        self.total_data.columns\n",
    "        self.total_data.name = self.total_data.name.astype(str)\n",
    "        self.names_array = np.array(self.total_data[\"name\"].values.tolist())\n",
    "        \n",
    "    def preproc_names(self, name):\n",
    "        \"\"\"\n",
    "        removes special characters and punctuation from the names, turns all to lower cases for uniformity\n",
    "        Preserves space as it is valid in between name blocks\n",
    "        \"\"\"\n",
    "        name_ = \"\".join([i for i in name if i not in string.punctuation])\n",
    "        name_ = name_.lower()\n",
    "        \n",
    "        return name_\n",
    "    \n",
    "    def create_names_matrix(self, x):\n",
    "        \"\"\"\n",
    "        converts names into matrix embedding of given maximum length and total features categories\n",
    "        Here:- 68X27\n",
    "        68:- total word length\n",
    "        27:- 26 alphabets plus 1 for space\n",
    "        \n",
    "        \"\"\"\n",
    "        names_matrix = np.zeros((self.max_name_len_ext,27))\n",
    "        for i in range(len(x)):\n",
    "            try:\n",
    "                names_matrix[i][string.ascii_lowercase.index(x[i])]=1\n",
    "            except:\n",
    "                names_matrix[i][-1]=1\n",
    "                \n",
    "        return names_matrix\n",
    "    \n",
    "    def split_data(self):\n",
    "        \"\"\"\n",
    "        splits data into data dictionaries and prepares sequential data in terms of slide_kernel created\n",
    "        \"\"\"\n",
    "        self.names_array_v2=np.array([self.preproc_names(z) for z in self.names_array])\n",
    "        self.max_name_len = max([len(x) for x in self.names_array_v2])\n",
    "        self.max_name_len_ext = max([len(x) for x in self.names_array_v2])+10\n",
    "        names_indexes=list(range(len(self.names_array_v2)))\n",
    "        names_dict = {}\n",
    "        names_matrix_dict = {}\n",
    "        for i in names_indexes:\n",
    "            names_dict[i]=self.names_array_v2[i]\n",
    "            names_matrix_dict[i]=self.create_names_matrix(self.names_array_v2[i])\n",
    "        self.split_data_dict={}\n",
    "        train_len = int(len(names_dict)*self.split_ratio)\n",
    "        print(train_len)\n",
    "        train_indices = random.sample(range(0, len(names_dict)), train_len)\n",
    "        test_indices = list(set(list(range(len(names_dict)))) -set(train_indices))\n",
    "        self.split_data_dict[\"train_indices\"]=train_indices\n",
    "        self.split_data_dict[\"test_indices\"]=test_indices\n",
    "        self.train_names_dict = {}\n",
    "        self.test_names_dict = {}\n",
    "        self.train_data_dict = {}\n",
    "        self.test_data_dict = {}\n",
    "        for i in self.split_data_dict[\"train_indices\"]:\n",
    "            self.train_data_dict[i] = names_matrix_dict[i]\n",
    "            self.train_names_dict[i] = names_dict[i]\n",
    "        for j in self.split_data_dict[\"test_indices\"]:\n",
    "            self.test_data_dict[j] = names_matrix_dict[j]\n",
    "            self.test_names_dict[j] = names_dict[j]\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def create_data(self,slide_kernel):\n",
    "        \"\"\"\n",
    "        creates data given the slide_kernel length and saves the data in usable array\n",
    "        prints shape of data arrays created\n",
    "        \"\"\"\n",
    "        self.slide_kernel = slide_kernel\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        for j in self.train_data_dict:\n",
    "            for i in range(0, self.max_name_len_ext - self.slide_kernel, 1):\n",
    "                seq_in = self.train_data_dict[j][i:i + self.slide_kernel]\n",
    "                if np.count_nonzero(seq_in)!=0:\n",
    "                    seq_out = self.train_data_dict[j][i + self.slide_kernel]\n",
    "                    dataX.append(seq_in)\n",
    "                    dataY.append(seq_out)\n",
    "                else:\n",
    "                    pass\n",
    "        dataX_test = []\n",
    "        dataY_test = []\n",
    "        for j in self.test_data_dict:\n",
    "            for i in range(0, self.max_name_len_ext - self.slide_kernel, 1):\n",
    "                seq_in_test = self.test_data_dict[j][i:i + self.slide_kernel]\n",
    "                if np.count_nonzero(seq_in_test)!=0:\n",
    "                    seq_out_test = self.test_data_dict[j][i + self.slide_kernel]\n",
    "                    dataX_test.append(seq_in_test)\n",
    "                    dataY_test.append(seq_out_test)\n",
    "                else:\n",
    "                    pass \n",
    "        \n",
    "        assert len(dataX) == len(dataY)\n",
    "        assert len(dataX_test) == len(dataY_test)\n",
    "        \n",
    "        n_patterns = len(dataX)\n",
    "        print(n_patterns)\n",
    "        \n",
    "        n_patterns_test = len(dataX_test)\n",
    "        print(n_patterns_test)\n",
    "\n",
    "        self.dataX_arr = np.array(dataX)\n",
    "        print(self.dataX_arr.shape)\n",
    "\n",
    "        self.dataY_arr = np.array(dataY)\n",
    "        print(self.dataY_arr.shape)\n",
    "        \n",
    "        self.dataX_test_arr = np.array(dataX_test)\n",
    "        print(self.dataX_test_arr.shape)\n",
    "\n",
    "        self.dataY_test_arr = np.array(dataY_test)\n",
    "        print(self.dataY_test_arr.shape)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def save_data(self,data,name):\n",
    "        \"\"\"\n",
    "        function to save data in compressed bz2 file format for efficient storage of data and models\n",
    "        \"\"\"\n",
    "        save_handle = bz2.BZ2File(self.save_data_path + name, 'wb')\n",
    "        pickle.dump(data, save_handle)\n",
    "        save_handle.close()\n",
    "        \n",
    "    def data_saver_all(self):\n",
    "        \"\"\"\n",
    "        main function that saves everthing\n",
    "        \"\"\"\n",
    "        xtrain_savename = \"dataX_train_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.dataX_arr,xtrain_savename)\n",
    "        print(xtrain_savename)\n",
    "        \n",
    "        ytrain_savename = \"dataY_train_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.dataY_arr,ytrain_savename)\n",
    "        print(ytrain_savename)\n",
    "        \n",
    "        xtest_savename = \"dataX_test_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.dataX_test_arr,xtest_savename)\n",
    "        print(xtest_savename)\n",
    "        \n",
    "        ytest_savename = \"dataY_test_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.dataY_test_arr,ytest_savename)\n",
    "        print(ytest_savename)\n",
    "\n",
    "        train_names_dict_name = \"train_names_dict_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.train_names_dict,train_names_dict_name)\n",
    "        print(train_names_dict_name)\n",
    "        \n",
    "        train_data_dict_name = \"train_data_dict_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.train_data_dict,train_data_dict_name)\n",
    "        print(train_data_dict_name)\n",
    "        \n",
    "        test_names_dict_name = \"test_names_dict_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.test_names_dict,test_names_dict_name)\n",
    "        print(test_names_dict_name)\n",
    "        \n",
    "        test_data_dict_name = \"test_data_dict_krnl_\"+str(self.slide_kernel)+\".bz2\"\n",
    "        self.save_data(self.test_data_dict,test_data_dict_name)\n",
    "        print(test_data_dict_name)\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
